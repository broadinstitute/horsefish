{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Repository Service (DRS) URI Access Examination\n",
    "\n",
    "\n",
    "In this notebook, we get all the DRS URIs from the data table and check if we can access the file each DRS URI points to. \n",
    "\n",
    "This notebook will:\n",
    "1. Grab all DRS URIs from the data table\n",
    "2. Resolve each DRS URI and check our access to the file\n",
    "3. Create a report with all the DRS URIs and our access level to each of them\n",
    "\n",
    "This Notebook will run successfully with the default Terra Cloud Environment with 4 CPUs.\n",
    "For improved performance when testing a substantial number of DRS URIs in a workspace (> 10,000) increasing the number of Cloud Environment CPUs to 16 is recommended.\n",
    "\n",
    "## Background\n",
    "\n",
    "\n",
    "The Data Repository Service (DRS) API is a standardized set of access methods that are agnostic to cloud infrastructure. Developed by the Global Alliance for Genomics and Health (GA4GH), DRS enable researchers to access data regardless of the underlying architecture of the repository (i.e. Google Cloud, Azure, AWS, etc.) in which it is stored. Terra supports accessing data using the GA4GH standard Data Repository Service (DRS). To learn more look at this link: https://support.terra.bio/hc/en-us/articles/360039330211-Data-Access-with-the-GA4GH-Data-Repository-Service-DRS- \n",
    "\n",
    "## Setup \n",
    "\n",
    "To run code from the terra-notebook-utils, tabulate, and tqdm library, we first have to install the packages and restart the kernel. \n",
    "\n",
    "1. Run the cell below\n",
    "2. Go to the kernel tab in the menu at the top, and select restart\n",
    "3. Press the restart in the pop-up menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/DataBiosphere/terra-notebook-utils\n",
      "  Cloning https://github.com/DataBiosphere/terra-notebook-utils to /tmp/pip-req-build-nyr2bvkg\n",
      "  Running command git clone -q https://github.com/DataBiosphere/terra-notebook-utils /tmp/pip-req-build-nyr2bvkg\n",
      "Collecting google-cloud-storage==1.31.2\n",
      "  Downloading google_cloud_storage-1.31.2-py2.py3-none-any.whl (88 kB)\n",
      "\u001b[K     |████████████████████████████████| 88 kB 6.0 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting gs-chunked-io<0.6,>=0.5.1\n",
      "  Downloading gs-chunked-io-0.5.2.tar.gz (8.1 kB)\n",
      "Collecting firecloud\n",
      "  Downloading firecloud-0.16.31.tar.gz (53 kB)\n",
      "\u001b[K     |████████████████████████████████| 53 kB 17.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting bgzip<0.4,>=0.3.5\n",
      "  Downloading bgzip-0.3.5.tar.gz (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 10.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cli-builder<0.2,>=0.1.5\n",
      "  Downloading cli-builder-0.1.5.tar.gz (3.5 kB)\n",
      "Collecting oauth2client\n",
      "  Downloading oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 14.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jmespath==0.10.0\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting google-auth<2.0dev,>=1.11.0\n",
      "  Downloading google_auth-1.30.0-py2.py3-none-any.whl (146 kB)\n",
      "\u001b[K     |████████████████████████████████| 146 kB 9.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-cloud-core<2.0dev,>=1.4.1\n",
      "  Downloading google_cloud_core-1.6.0-py2.py3-none-any.whl (28 kB)\n",
      "Collecting google-resumable-media<2.0dev,>=1.0.0\n",
      "  Downloading google_resumable_media-1.2.0-py2.py3-none-any.whl (75 kB)\n",
      "\u001b[K     |████████████████████████████████| 75 kB 18.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests<3.0.0dev,>=2.18.0\n",
      "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 18.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 12.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting six>=1.9.0\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting setuptools>=40.3.0\n",
      "  Downloading setuptools-56.1.0-py3-none-any.whl (785 kB)\n",
      "\u001b[K     |████████████████████████████████| 785 kB 13.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-api-core<2.0.0dev,>=1.21.0\n",
      "  Downloading google_api_core-1.26.3-py2.py3-none-any.whl (93 kB)\n",
      "\u001b[K     |████████████████████████████████| 93 kB 16.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting googleapis-common-protos<2.0dev,>=1.6.0\n",
      "  Downloading googleapis_common_protos-1.53.0-py2.py3-none-any.whl (198 kB)\n",
      "\u001b[K     |████████████████████████████████| 198 kB 14.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting protobuf>=3.12.0\n",
      "  Downloading protobuf-3.15.8-cp37-cp37m-manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 13.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pytz\n",
      "  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
      "\u001b[K     |████████████████████████████████| 510 kB 16.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting packaging>=14.3\n",
      "  Downloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
      "\u001b[K     |████████████████████████████████| 40 kB 57.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-crc32c<2.0dev,>=1.0\n",
      "  Downloading google_crc32c-1.1.2-cp37-cp37m-manylinux2014_x86_64.whl (38 kB)\n",
      "Collecting cffi>=1.0.0\n",
      "  Downloading cffi-1.14.5-cp37-cp37m-manylinux1_x86_64.whl (402 kB)\n",
      "\u001b[K     |████████████████████████████████| 402 kB 17.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pycparser\n",
      "  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
      "\u001b[K     |████████████████████████████████| 112 kB 18.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyparsing>=2.0.2\n",
      "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "\u001b[K     |████████████████████████████████| 67 kB 21.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 18.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.4-py2.py3-none-any.whl (153 kB)\n",
      "\u001b[K     |████████████████████████████████| 153 kB 13.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting certifi>=2017.4.17\n",
      "  Downloading certifi-2020.12.5-py2.py3-none-any.whl (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 14.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting chardet<5,>=3.0.2\n",
      "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "\u001b[K     |████████████████████████████████| 178 kB 14.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting idna<3,>=2.5\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 12.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pydot\n",
      "  Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Collecting nose\n",
      "  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
      "\u001b[K     |████████████████████████████████| 154 kB 13.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pylint==1.7.2\n",
      "  Downloading pylint-1.7.2-py2.py3-none-any.whl (644 kB)\n",
      "\u001b[K     |████████████████████████████████| 644 kB 13.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting mccabe\n",
      "  Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n",
      "Collecting isort>=4.2.5\n",
      "  Downloading isort-5.8.0-py3-none-any.whl (103 kB)\n",
      "\u001b[K     |████████████████████████████████| 103 kB 22.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astroid>=1.5.1\n",
      "  Downloading astroid-2.5.6-py3-none-any.whl (219 kB)\n",
      "\u001b[K     |████████████████████████████████| 219 kB 17.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typed-ast<1.5,>=1.4.0\n",
      "  Downloading typed_ast-1.4.3-cp37-cp37m-manylinux1_x86_64.whl (743 kB)\n",
      "\u001b[K     |████████████████████████████████| 743 kB 17.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting lazy-object-proxy>=1.4.0\n",
      "  Downloading lazy_object_proxy-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (55 kB)\n",
      "\u001b[K     |████████████████████████████████| 55 kB 45.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wrapt<1.13,>=1.11\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting httplib2>=0.9.1\n",
      "  Downloading httplib2-0.19.1-py3-none-any.whl (95 kB)\n",
      "\u001b[K     |████████████████████████████████| 95 kB 23.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cryptography>=1.3.4\n",
      "  Downloading cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2 MB 18.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyOpenSSL>=0.14\n",
      "  Downloading pyOpenSSL-20.0.1-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[K     |████████████████████████████████| 54 kB 42.5 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: terra-notebook-utils, bgzip, cli-builder, gs-chunked-io, firecloud, wrapt\n",
      "  Building wheel for terra-notebook-utils (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for terra-notebook-utils: filename=terra_notebook_utils-0.8.1-py3-none-any.whl size=42434 sha256=d7b58381a8286e3634688e92140c386fed9824daf31e693c4258a6b706c1f39d\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-vo74bmls/wheels/b7/d9/9f/c25a763a4da619ca50a8ee11c6fb38a7a644bc117084dd3a43\n",
      "  Building wheel for bgzip (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bgzip: filename=bgzip-0.3.5-cp37-cp37m-linux_x86_64.whl size=138606 sha256=1194afeda1f23d0232b932bd6ff325c4d423917d746504b774b5a3c1f413929b\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-vo74bmls/wheels/63/45/84/5431b7bd7c1bb0e34edb3d6bf2475ff027f95fc115107dbb19\n",
      "  Building wheel for cli-builder (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for cli-builder: filename=cli_builder-0.1.5-py3-none-any.whl size=4665 sha256=d37448c1b0bdb0714572ac695f3e08bfb1594c6ccb85c8c1e7ecb19ff03e4d93\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-vo74bmls/wheels/37/6a/3e/e60dde5f88da7d86b24c1cc79f206fd73f6a621ad1bfe27961\n",
      "  Building wheel for gs-chunked-io (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gs-chunked-io: filename=gs_chunked_io-0.5.2-py3-none-any.whl size=11265 sha256=837bdfb04fe64fb1a590ef919e957117f235427bea81fa3c072667eb8a49ed44\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-vo74bmls/wheels/d9/17/31/ce24f67f7553e48d320f575bb0f91006ad96402af8a460b3eb\n",
      "  Building wheel for firecloud (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for firecloud: filename=firecloud-0.16.31-py3-none-any.whl size=56804 sha256=7126430acded8ecb8ab93d2cf3f948a59bacfcfb1484120985436f7f52d98266\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-vo74bmls/wheels/df/5d/2a/cd382b7648f96c90a2fd0114807d83697c9a6c217b0d07d9fe\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=70541 sha256=e7cef06d42d856f9fe336f8f2efdc70f75882faa8044e37bde5c0dadc0eb7a08\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-vo74bmls/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
      "Successfully built terra-notebook-utils bgzip cli-builder gs-chunked-io firecloud wrapt\n",
      "Installing collected packages: six, pyasn1, urllib3, setuptools, rsa, pyparsing, pycparser, pyasn1-modules, protobuf, idna, chardet, certifi, cachetools, requests, pytz, packaging, googleapis-common-protos, google-auth, cffi, wrapt, typed-ast, lazy-object-proxy, google-crc32c, google-api-core, cryptography, pyOpenSSL, mccabe, isort, google-resumable-media, google-cloud-core, astroid, pylint, pydot, nose, httplib2, google-cloud-storage, oauth2client, jmespath, gs-chunked-io, firecloud, cli-builder, bgzip, terra-notebook-utils\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-cloud-bigquery 1.23.1 requires google-resumable-media!=0.4.0,<0.6.0dev,>=0.3.1, but you have google-resumable-media 1.2.0 which is incompatible.\u001b[0m\n",
      "Successfully installed astroid-2.5.6 bgzip-0.3.5 cachetools-4.2.2 certifi-2020.12.5 cffi-1.14.5 chardet-4.0.0 cli-builder-0.1.5 cryptography-3.4.7 firecloud-0.16.31 google-api-core-1.26.3 google-auth-1.30.0 google-cloud-core-1.6.0 google-cloud-storage-1.31.2 google-crc32c-1.1.2 google-resumable-media-1.2.0 googleapis-common-protos-1.53.0 gs-chunked-io-0.5.2 httplib2-0.19.1 idna-2.10 isort-5.8.0 jmespath-0.10.0 lazy-object-proxy-1.6.0 mccabe-0.6.1 nose-1.3.7 oauth2client-4.1.3 packaging-20.9 protobuf-3.15.8 pyOpenSSL-20.0.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycparser-2.20 pydot-1.4.2 pylint-1.7.2 pyparsing-2.4.7 pytz-2021.1 requests-2.25.1 rsa-4.7.2 setuptools-56.1.0 six-1.16.0 terra-notebook-utils-0.8.1 typed-ast-1.4.3 urllib3-1.26.4 wrapt-1.12.1\n",
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting tabulate\n",
      "  Using cached tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Installing collected packages: tabulate\n",
      "Successfully installed tabulate-0.8.9\n",
      "\u001b[33mWARNING: Target directory /home/jupyter-user/notebooks/packages/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter-user/notebooks/packages/tabulate.py already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter-user/notebooks/packages/tabulate-0.8.9.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter-user/notebooks/packages/bin already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.60.0-py2.py3-none-any.whl (75 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.60.0\n",
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Installing terra-notebook-utils, tabulate, and tqdm library\n",
    "!pip install --upgrade --no-cache-dir git+https://github.com/DataBiosphere/terra-notebook-utils\n",
    "!pip install tabulate\n",
    "!pip install tqdm -U\n",
    "\n",
    "# Configuring notebook log level to log if the DRS URI has access\n",
    "import logging\n",
    "%config Application.log_level = \"INFO\"  \n",
    "log = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set DRS URI Column Location \n",
    "\n",
    "The DRS URIs' columns location varies per data table varies. The default for this notebook is BioData Catalyst data. Base on your data can choose from biodata-catalyst, anvil, and tcga. If your data is not from one of these three categories, please type the column name of where the DRS URIs are stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Set variable to either \"biodata-catalyst\", \"anvil\", \"tcga\", or \"<INSERT DRS URIs' column name>\"\n",
    "columns_name = \"tcga\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Head Variable\n",
    "\n",
    "The head variable is an optional variable that allows you to run the notebook on the first 10 DRS URIs instead of the all the DRS URIs in the data table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to True if you want to runs the notebook on the first 10 DRS uri in the data table \n",
    "head = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab all DRS URIs from the data table\n",
    "\n",
    "The DRS URI is stored under the object_id column in a table.\n",
    "\n",
    "Using the firecloud library, we are going to search for the object_id column in each table in the data table. If a table contains an object_id column, we check if the content is a string and has 'drs://' at its beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# set imports and environment variables\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import sys\n",
    "import threading\n",
    "from pytz import timezone\n",
    "from datetime import datetime\n",
    "from firecloud import api as fapi\n",
    "from subprocess import Popen, PIPE\n",
    "from tabulate import tabulate\n",
    "from terra_notebook_utils import drs, table\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Getting the namespace/project and name of the workspace\n",
    "namespace = os.environ['WORKSPACE_NAMESPACE']\n",
    "workspace = os.environ['WORKSPACE_NAME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3406 DRS uris in this workspace\n"
     ]
    }
   ],
   "source": [
    "# Assigning column search key (Add workspace option)  #TODO: Ask micheal about \"ga4gh_drs_uri\"\n",
    "data_column_map = {\"biodata-catalyst\":[\"object_id\"], \"anvil\":[\"object_id\"]}\n",
    "\n",
    "# if dataset is \"tcga\" add list of unique cols - want to search for DRS uris in all cols in all tables\n",
    "if columns_name == \"tcga\":\n",
    "    tcga_cols = set()\n",
    "    for e in data_tables_list:\n",
    "        key_list = list(e[\"attributes\"].keys())\n",
    "        tcga_cols.update([key for key in key_list])\n",
    "    data_column_map[\"tcga\"] = list(tcga_cols)\n",
    "    \n",
    "\n",
    "# get each table's entities with attributes and type \n",
    "data_tables_list = fapi.get_entities_with_type(namespace, workspace).json()\n",
    "\n",
    "# Creating the master DRS URIs dictionary \n",
    "DRS_uris_dict = {}\n",
    "\n",
    "# Going through each item in response (aka one row/entity in all rows from all tables)\n",
    "for table in data_tables_list:\n",
    "    table_columns = table[\"attributes\"]  # tuples (col_name, val)\n",
    "    # if columnns for an entity in tcga dict list, add row/entity to dictionary\n",
    "    object_id_column = dict(filter(lambda column: column[0] in data_column_map[column_name_search_key], table_columns.items()))\n",
    "    \n",
    "    # Checking if the object_id column's contents is a string and start with 'drs://' \n",
    "    if object_id_column:\n",
    "        for col, val in object_id_column.items():\n",
    "            if type(val) is str and val.startswith('drs://'):\n",
    "                DRS_uris_dict[val] = {'table_name': table['entityType'], \n",
    "                                       'row_id' : table['name'], \n",
    "                                       'drs_uri' : val}\n",
    "\n",
    "                # Outputting the amount of DRS URIs found\n",
    "print(f\"Found {len(DRS_uris_dict)} DRS uris in this workspace\")\n",
    "\n",
    "# If head is true, runs the notebook on the first 10 DRS URI in the data table            \n",
    "if head:\n",
    "    for i in range(len(DRS_uris_dict)-1):\n",
    "        DRS_uris_dict.popitem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resolve DRS URIs and Checking File Access\n",
    "\n",
    "DRS creates a unique ID mapping that allows for flexible file retrieval. The unique mapping is the DRS Uniform Resource Identifier (URI) - a string of characters that uniquely identifies a particular cloud-based resource (similar to URIs) and is agnostic to the cloud infrastructure where it physically exists. To learn where the file physically exists on the cloud, we must resolve the DRS through a backend service called Martha that will unmap the DRS URI to get the file's google bucket file path.\n",
    "\n",
    "In this step, we check if all the DRS URIs can be resolved and check our access to the file it points to in the google bucket. If the DRS URI can't be resolved, we will record the error that will, later on, be shown in the report in the last step.\n",
    "\n",
    "One of the most common reasons the DRS URIs can not resolve is \"Fence is not linked\". If you have this error, it is probably because the data is controlled-access. To use controlled-access data on Terra, you will need to link your Terra user ID to your authorization account (such as a dbGaP account). Linking to external servers will allow Terra to automatically determine if you can access controlled datasets hosted in Terra (ex. TCGA, TOPMed, etc.) based on your valid dbGaP applications. Go to this link to learn more: https://support.terra.bio/hc/en-us/articles/360038086332\n",
    "\n",
    "## Creating Resolve DRS URI Function \n",
    "\n",
    "The `resolve_drs_uri` fuction will resolve and check file access for a given DRS URI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_drs_uri(drs_url):\n",
    "    try:\n",
    "        # Trying to check access to file by reading the first 10 bytes\n",
    "        drs.head(drs_url)\n",
    "        \n",
    "        # Logging if the call succeed\n",
    "        log.info(f\"SUCCESS  : {drs_url}\")\n",
    "        \n",
    "        # Saving error to the DRS URI information dictionary\n",
    "        DRS_uris_dict[drs_url]['drs_unresolved_error'] = \"None\"\n",
    "    except drs.GSBlobInaccessible:\n",
    "        # Logging if the call failed\n",
    "        log.warning(f\"NO ACCESS: {drs_url}\")\n",
    "        # Saving the error if failed\n",
    "        error = sys.exc_info()[1]\n",
    "        if \" Error:\" in error:\n",
    "            error = str((sys.exc_info()[1])).split(\" Error:\")[1] \n",
    "            if \"ProviderUser\" in error:\n",
    "                error = error.split(\"ProviderUser\")[0]\n",
    "        \n",
    "        # Outputting the error to console\n",
    "        print(error)\n",
    "        \n",
    "        # Outputting the extra error info for the \"Fence account not linked\" error to console\n",
    "        if \"Fence account not linked\" in error:\n",
    "            print('''One of the most common reasons the DRS URIs can not resolve is \"Fence is not linked\". \n",
    "If you have this error, it is probably because the data is controlled-access. \n",
    "To use controlled-access data on Terra, you will need to link your Terra user ID to your authorization account (such as a dbGaP account). \n",
    "Linking to external servers will allow Terra to automatically determine if you can access controlled datasets hosted in Terra (ex. TCGA, TOPMed, etc.) based on your valid dbGaP applications. \n",
    "Go to this link to learn more: https://support.terra.bio/hc/en-us/articles/360038086332''')\n",
    "        \n",
    "        # Saving error to the DRS URI information dictionary\n",
    "        DRS_uris_dict[drs_url]['drs_unresolved_error'] = error\n",
    "    \n",
    "    # Returing the DRS URI information dictionary \n",
    "    return {drs_url : DRS_uris_dict[drs_url]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Resolve DRS URI Function\n",
    "\n",
    "Running all the DRS URI found through the resolve_drs_uri fuction in parallel groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolving 2 DRS uris\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b9735acd1374de78e9f6bbdfc72b745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-05 07:46:08::WARNING  NO ACCESS: drs://dg.4DFC:35520334-9761-4d4a-8852-12778565dfa1\n",
      "2021-05-05 07:46:09::WARNING  NO ACCESS: drs://dg.4DFC:dd86334f-95e7-4949-94d0-90e211ccdfa8\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "argument of type 'GSBlobInaccessible' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/jupyter-user/notebooks/packages/terra_notebook_utils/drs.py\", line 230, in head\n    client, info = resolve_drs_for_gs_storage(drs_url)\n  File \"/home/jupyter-user/notebooks/packages/terra_notebook_utils/drs.py\", line 178, in resolve_drs_for_gs_storage\n    info = resolve_drs_info_for_gs_storage(drs_url)\n  File \"/home/jupyter-user/notebooks/packages/terra_notebook_utils/drs.py\", line 164, in resolve_drs_info_for_gs_storage\n    drs_response: dict = fetch_drs_info(drs_url)\n  File \"/home/jupyter-user/notebooks/packages/terra_notebook_utils/drs.py\", line 92, in fetch_drs_info\n    raise DRSResolutionError(f\"Unexpected response while resolving DRS path. Expected status 200, got \"\nterra_notebook_utils.drs.DRSResolutionError: Unexpected response while resolving DRS path. Expected status 200, got 500. Error: Received error contacting Bond. The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"<ipython-input-29-91efd35ea763>\", line 4, in resolve_drs_uri\n    drs.head(drs_url)\n  File \"/home/jupyter-user/notebooks/packages/terra_notebook_utils/drs.py\", line 236, in head\n    raise GSBlobInaccessible(f'The DRS URL: {drs_url}\\n'\nterra_notebook_utils.drs.GSBlobInaccessible: The DRS URL: drs://dg.4DFC:35520334-9761-4d4a-8852-12778565dfa1\nCould not be accessed because of:\nTraceback (most recent call last):\n  File \"/home/jupyter-user/notebooks/packages/terra_notebook_utils/drs.py\", line 230, in head\n    client, info = resolve_drs_for_gs_storage(drs_url)\n  File \"/home/jupyter-user/notebooks/packages/terra_notebook_utils/drs.py\", line 178, in resolve_drs_for_gs_storage\n    info = resolve_drs_info_for_gs_storage(drs_url)\n  File \"/home/jupyter-user/notebooks/packages/terra_notebook_utils/drs.py\", line 164, in resolve_drs_info_for_gs_storage\n    drs_response: dict = fetch_drs_info(drs_url)\n  File \"/home/jupyter-user/notebooks/packages/terra_notebook_utils/drs.py\", line 92, in fetch_drs_info\n    raise DRSResolutionError(f\"Unexpected response while resolving DRS path. Expected status 200, got \"\nterra_notebook_utils.drs.DRSResolutionError: Unexpected response while resolving DRS path. Expected status 200, got 500. Error: Received error contacting Bond. The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.7/concurrent/futures/process.py\", line 239, in _process_worker\n    r = call_item.fn(*call_item.args, **call_item.kwargs)\n  File \"/usr/lib/python3.7/concurrent/futures/process.py\", line 198, in _process_chunk\n    return [fn(*args) for args in chunk]\n  File \"/usr/lib/python3.7/concurrent/futures/process.py\", line 198, in <listcomp>\n    return [fn(*args) for args in chunk]\n  File \"<ipython-input-32-e8a465d0cbdf>\", line 21, in check_batch\n    for drs_uri, temp_dict in zip(DRS_uris_dict_keys, e.map(resolve_drs_uri, DRS_uris_dict_keys)):\n  File \"/usr/lib/python3.7/concurrent/futures/_base.py\", line 598, in result_iterator\n    yield fs.pop().result()\n  File \"/usr/lib/python3.7/concurrent/futures/_base.py\", line 435, in result\n    return self.__get_result()\n  File \"/usr/lib/python3.7/concurrent/futures/_base.py\", line 384, in __get_result\n    raise self._exception\n  File \"/usr/lib/python3.7/concurrent/futures/thread.py\", line 57, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"<ipython-input-29-91efd35ea763>\", line 16, in resolve_drs_uri\n    if \" Error:\" in error:\nTypeError: argument of type 'GSBlobInaccessible' is not iterable\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-e8a465d0cbdf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Creating Pool of batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mProcessPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUMBER_OF_PROCESSES\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprime\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;31m# Updating DRS URI information dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mDRS_uris_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/notebooks/packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/notebooks/packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/concurrent/futures/process.py\u001b[0m in \u001b[0;36m_chain_from_iterable_of_lists\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0mcareful\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mto\u001b[0m \u001b[0mkeep\u001b[0m \u001b[0mreferences\u001b[0m \u001b[0mto\u001b[0m \u001b[0myielded\u001b[0m \u001b[0mobjects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m     \"\"\"\n\u001b[0;32m--> 483\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m         \u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    596\u001b[0m                     \u001b[0;31m# Careful not to keep a reference to the popped future\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m                         \u001b[0;32myield\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    433\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: argument of type 'GSBlobInaccessible' is not iterable"
     ]
    }
   ],
   "source": [
    "# Outputting the start of resolving DRS URIs\n",
    "print(\"Resolving \"+ str(len(DRS_uris_dict)) + \" DRS uris\")\n",
    "\n",
    "# Assigning the count variable to keep track of resolved DRS URIs\n",
    "resolved_DRS_uris_count = 0\n",
    "\n",
    "# Suppress DRS resolution info messages\n",
    "drs.logger.disabled = True \n",
    "\n",
    "# Setting the list of Threads\n",
    "NUMBER_OF_PROCESSES = 20\n",
    "THREADS_PER_PROCESS = 10\n",
    "\n",
    "# Creating batches of Threads\n",
    "def check_batch(DRS_uris_dict_keys):\n",
    "    # Creating temp DRS URI information dictionary \n",
    "    temp_DRS_uris_dict = {}\n",
    "    \n",
    "    # Creating threads for each DRS URIs\n",
    "    with ThreadPoolExecutor() as e:\n",
    "        for drs_uri, temp_dict in zip(DRS_uris_dict_keys, e.map(resolve_drs_uri, DRS_uris_dict_keys)):\n",
    "            # Updating DRS URI information dictionary \n",
    "            temp_DRS_uris_dict.update(temp_dict)\n",
    "    \n",
    "    # Returing the DRS URI information dictionary \n",
    "    return temp_DRS_uris_dict\n",
    "\n",
    "\n",
    "# Creating number of batches of Threads\n",
    "batches = [list(DRS_uris_dict.keys())[i:i+THREADS_PER_PROCESS]\n",
    "            for i in range(0, len(DRS_uris_dict.keys()), THREADS_PER_PROCESS)]\n",
    "\n",
    "# Creating Pool of batches\n",
    "with ProcessPoolExecutor(max_workers=NUMBER_OF_PROCESSES) as e:\n",
    "    for number, prime in tqdm(zip(batches, e.map(check_batch, batches)), total=len(batches)):\n",
    "        # Updating DRS URI information dictionary \n",
    "        DRS_uris_dict.update(prime)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a report\n",
    "\n",
    "In this report, we will first print out statistics of the DRS URI data. The information record in the statistics is DRS URIs that were found in the workspace, that were resolved, that were unresolved. Also, files with and without access. Lastly, errors from DRS URIs that are not resolved or files without access.\n",
    "\n",
    "The second part of the report is the table of DRS URI data that includes the columns: table_name, row_id, drs_uri, drs_unresolved_error, file_access_error, file_path, is_resolved, and file_access \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if there is unresolved_DRS_URIs_errors to report\n",
    "unresolved_DRS_uris_errors_list = []\n",
    "for value in DRS_uris_dict.values():\n",
    "    if value['drs_unresolved_error'] not in 'None':\n",
    "        unresolved_DRS_uris_errors_list.append(value['drs_unresolved_error'])\n",
    "    \n",
    "if unresolved_DRS_uris_errors_list:\n",
    "    unresolved_DRS_uris_errors = \", \".join(set(unresolved_DRS_uris_errors_list))\n",
    "    if any(\"Fence account not linked\" in errors for errors in unresolved_DRS_uris_errors_list):\n",
    "        unresolved_DRS_uris_errors =  unresolved_DRS_uris_errors + ''' ~ One of the most common reasons the DRS URIs can not resolve is \"Fence is not linked\". \n",
    "If you have this error, it is probably because the data is controlled-access. \n",
    "To use controlled-access data on Terra, you will need to link your Terra user ID to your authorization account (such as a dbGaP account). \n",
    "Linking to external servers will allow Terra to automatically determine if you can access controlled datasets hosted in Terra (ex. TCGA, TOPMed, etc.) based on your valid dbGaP applications. \n",
    "Go to this link to learn more: https://support.terra.bio/hc/en-us/articles/360038086332'''\n",
    "else:\n",
    "    unresolved_DRS_uris_errors = \"None\"\n",
    "    \n",
    "    \n",
    "# Setting the title for the report\n",
    "title = \"Data Repository Service (DRS) URI Access Examination Report\"\n",
    "\n",
    "# Creating the statistics for the report\n",
    "stats = f'''\n",
    "\n",
    "DRS URIs found in the workspace: {len(DRS_uris_dict)} \\n\n",
    "        \n",
    "DRS URIs resolved: {len(DRS_uris_dict)-len(unresolved_DRS_uris_errors_list)}\n",
    " \n",
    "DRS URIs not resolved: {len(unresolved_DRS_uris_errors_list)}\n",
    "        \n",
    "Errors found from DRS URIs that are not resolved: {len(unresolved_DRS_uris_errors_list)}\n",
    "        \n",
    "Distinct errors from DRS URIs that are not resolved: {unresolved_DRS_uris_errors}\n",
    "'''\n",
    "\n",
    "# Outputting statistics\n",
    "print(f'''\n",
    "_______________________________________________________________________\n",
    "\n",
    ":: {title} ::\n",
    "_______________________________________________________________________\n",
    "\n",
    "{stats}''')\n",
    "\n",
    "\n",
    "\n",
    "# Outputting the table of the master DRS URIs dictionary\n",
    "pd.DataFrame.from_dict(DRS_uris_dict).transpose()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Save results to the Google Bucket\n",
    "\n",
    "To save the results in a HTML file in the google bucket, please run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Report to HTML format \n",
    "html_report = f'''<html lang=\"en\">\n",
    "<head>\n",
    "<title>{title}</title>''' + '''\n",
    "<meta charset=\"utf-8\">\n",
    "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
    "<style>\n",
    "* {\n",
    "  box-sizing: border-box;\n",
    "}\n",
    "\n",
    "body {\n",
    "  font-family: Arial, Helvetica, sans-serif;\n",
    "}\n",
    "\n",
    "/* Style the header */\n",
    "header {\n",
    "  background-color: #73af42;\n",
    "  padding: 30px;\n",
    "  text-align: center;\n",
    "  font-size: 35px;\n",
    "  color: white;\n",
    "}\n",
    "\n",
    "/* Create boxes that floats next to each other */\n",
    "article {\n",
    "  float: left;\n",
    "  padding: 20px;\n",
    "  width: 100%;\n",
    "  background-color: #f7f7f7;\n",
    "  height: 300px; /* only for demonstration, should be removed */\n",
    "}\n",
    "\n",
    "/* Style the list inside the menu */\n",
    "article ul {\n",
    "  list-style-type: none;\n",
    "  padding: 0;\n",
    "}\n",
    "\n",
    "/* Clear floats after the columns */\n",
    "section:after {\n",
    "  content: \"\";\n",
    "  display: table;\n",
    "  clear: both;\n",
    "}\n",
    "\n",
    "/* Style the footer */\n",
    "footer {\n",
    "  background-color: white;\n",
    "  padding: 10px;\n",
    "  text-align: center;\n",
    "  color: white;\n",
    "}\n",
    "\n",
    "/* Responsive layout - makes the two columns/boxes stack on top of each other instead of next to each other, on small screens */\n",
    "@media (max-width: 600px) {\n",
    "  nav, article {\n",
    "    width: 100%;\n",
    "    height: auto;\n",
    "  }\n",
    "}\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "''' + f'''\n",
    "<header>\n",
    "  <h2>{title}</h2>\n",
    "</header>\n",
    "<section>\n",
    "''' + f'''\n",
    "  <article>\n",
    "    <h2>\n",
    "        <ul>\n",
    "          <li>DRS URIs found in the workspace: {len(DRS_uris_dict)}</li>\n",
    "          <li>DRS URIs resolved: {len(DRS_uris_dict)-len(unresolved_DRS_uris_errors_list)}</li>\n",
    "          <li>DRS URIs not resolved: {len(unresolved_DRS_uris_errors_list)}</li>\n",
    "          <li>Errors found from DRS URIs that are not resolved: {len(unresolved_DRS_uris_errors_list)}</li>\n",
    "          <li>Distinct errors from DRS URIs that are not resolved: {unresolved_DRS_uris_errors}</li>\n",
    "        </ul>\n",
    "      </h2>\n",
    "  </article>\n",
    "</section>\n",
    "<footer>\n",
    "  <p>{tabulate(pd.DataFrame.from_dict(DRS_uris_dict).transpose(), headers='keys', tablefmt=\"html\")}</p>\n",
    "</footer>\n",
    "\n",
    "</body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "# Getting Timezone\n",
    "tz = timezone('EST')\n",
    "\n",
    "# Getting Today Date and Time\n",
    "today = datetime.now(tz).strftime('%Y_%m_%d_%H_%M_%S')\n",
    "\n",
    "# HTML File Name\n",
    "html_file_name = f\"DRS_URI_Access_Examination_{today}.html\"\n",
    "\n",
    "# Creating the DRS_URI_Access_Examination.html file\n",
    "with open(html_file_name, \"w\") as f:\n",
    "    f.write(html_report)\n",
    "\n",
    "# Getting the bucket path of the workspace\n",
    "WORKSPACE_BUCKET = os.environ['WORKSPACE_BUCKET']\n",
    "\n",
    "# Getting the bucket id of the workspace\n",
    "bucket_id = str(WORKSPACE_BUCKET).replace(\"gs://\", \"\")\n",
    "\n",
    "# Copying the DRS_URI_Access_Examination.html file to the google bucket\n",
    "!gsutil cp {html_file_name} {WORKSPACE_BUCKET}/ 2>&1\n",
    "\n",
    "# Printing path to the report file in the google bucket\n",
    "print(\"\\n TO View Result go to https://console.cloud.google.com/storage/browser/_details/\" + bucket_id + \"/\" + html_file_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
