{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workspace name = anvil_cmg_ingest_resources\n",
      "workspace project = dsp-data-ingest\n",
      "workspace bucket = gs://fc-9cd4583e-7855-4b5e-ae88-d8971cfd5b46\n"
     ]
    }
   ],
   "source": [
    "## imports and environment variables\n",
    "# imports\n",
    "import json\n",
    "import os\n",
    "import urllib3\n",
    "from google.cloud import storage\n",
    "import google.auth\n",
    "import google.auth.transport.requests\n",
    "import polling2\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "from dataclasses import asdict, dataclass, field\n",
    "from dataclasses_json import config, dataclass_json\n",
    "\n",
    "from typing import List, Optional\n",
    "from enum import Enum\n",
    "from urllib.parse import quote, urlparse, urlunparse\n",
    "from requests import Request, Response, Session\n",
    "\n",
    "# workspace environment variables\n",
    "ws_name = os.environ[\"WORKSPACE_NAME\"]\n",
    "ws_project = os.environ[\"WORKSPACE_NAMESPACE\"]\n",
    "ws_bucket = os.environ[\"WORKSPACE_BUCKET\"]\n",
    "\n",
    "print(f\"workspace name = {ws_name}\")\n",
    "print(f\"workspace project = {ws_project}\")\n",
    "print(f\"workspace bucket = {ws_bucket}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "class RestClient(ABC):\n",
    "    \"\"\"Provides a small wrapper around the requests library.\n",
    "\n",
    "    Could be useful for hooking in additional functionality in the future.\n",
    "    \"\"\"\n",
    "\n",
    "    def _get(self, url, **kwargs) -> Request:\n",
    "        return Request(\"get\", url, **kwargs)\n",
    "\n",
    "    def _post(self, url, **kwargs) -> Request:\n",
    "        return Request(\"post\", url, **kwargs)\n",
    "\n",
    "    def _put(self, url, **kwargs) -> Request:\n",
    "        return Request(\"put\", url, **kwargs)\n",
    "\n",
    "    def _delete(self, url, **kwargs) -> Request:\n",
    "        return Request(\"delete\", url, **kwargs)\n",
    "\n",
    "    def send(self, request: Request, **kwargs) -> Response:\n",
    "        \"\"\"Prepare and send a request. Return the response\n",
    "\n",
    "        IMPORTANT: Skips ssl cert validation for the time being.\n",
    "        \"\"\"\n",
    "        with Session() as session:\n",
    "            prepared = request.prepare()\n",
    "            response = session.send(prepared, verify=False, **kwargs)\n",
    "\n",
    "        return response\n",
    "\n",
    "    def stream_to_file(self, outfile, request: Request, **kwargs) -> int:\n",
    "        \"\"\"Prepare and send a request. Return the response\n",
    "\n",
    "        IMPORTANT: Skips ssl cert validation for the time being.\n",
    "        \"\"\"\n",
    "        n_bytes = 0\n",
    "        with Session() as session:\n",
    "            prepared = request.prepare()\n",
    "            with session.send(\n",
    "                prepared,\n",
    "                stream=True,\n",
    "                verify=False,\n",
    "                **kwargs,\n",
    "            ) as r:\n",
    "                # Ensure the request was successful\n",
    "                r.raise_for_status()\n",
    "                # Chunk size not guarunteed see:\n",
    "                # https://docs.python-requests.org/en/latest/api/#requests.Response.iter_content\n",
    "\n",
    "                for chunk in r.iter_content(chunk_size=1024 * 8):\n",
    "                    outfile.write(chunk)\n",
    "                    n_bytes += len(chunk)\n",
    "        return n_bytes\n",
    "\n",
    "\n",
    "class AuthenticatedClient(RestClient):\n",
    "    @abstractmethod\n",
    "    def authenticate(self, request):\n",
    "        \"\"\"Abstract method that will be called to authenticate\n",
    "        a Request before it is sent.\n",
    "        \"\"\"\n",
    "\n",
    "    def send(self, request: Request, **kwargs) -> Response:\n",
    "        \"\"\"Authenticate and then send request.\n",
    "\n",
    "        Params:\n",
    "            request: Request = Original unauthenticated request\n",
    "\n",
    "        Returns: Response\n",
    "        \"\"\"\n",
    "        authenticated_request = self.authenticate(request)\n",
    "        return super().send(authenticated_request, **kwargs)\n",
    "    \n",
    "\n",
    "\n",
    "class DataTypeEnum(Enum):\n",
    "    STRING = \"string\"\n",
    "    BOOLEAN = \"boolean\"\n",
    "    BYTES = \"bytes\"\n",
    "    DATE = \"date\"\n",
    "    DATETIME = \"datetime\"\n",
    "    DIRREF = \"dirref\"\n",
    "    FILERER = \"fileref\"\n",
    "    FLOAT = \"float\"\n",
    "    FLOAT64 = \"float64\"\n",
    "    INTEGER = \"integer\"\n",
    "    INT64 = \"int64\"\n",
    "    NUMERIC = \"numeric\"\n",
    "    RECORD = \"record\"\n",
    "    TEXT = \"text\"\n",
    "    TIME = \"time\"\n",
    "    TIMESTAMP = \"timestamp\"\n",
    "\n",
    "\n",
    "class ParititionModeEnum(Enum):\n",
    "    NONE = \"none\"\n",
    "    DATE = \"date\"\n",
    "    INT = \"int\"\n",
    "\n",
    "\n",
    "class CloudPlatformEnum(Enum):\n",
    "    GCP = \"gcp\"\n",
    "    AZURE = \"azure\"\n",
    "\n",
    "\n",
    "class FormatEnum(Enum):\n",
    "    CSV = \"csv\"\n",
    "    JSON = \"json\"\n",
    "    ARRAY = \"array\"\n",
    "\n",
    "\n",
    "class UpdateEnum(Enum):\n",
    "    APPEND = \"append\"\n",
    "    REPLACE = \"replace\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TDRResponse:\n",
    "    id: str\n",
    "    job_status: str\n",
    "    status_code: int\n",
    "    description: Optional[str] = None\n",
    "    submitted: Optional[str] = None\n",
    "    completed: Optional[str] = None\n",
    "    class_name: Optional[str] = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TDRErrorResponse:\n",
    "    message: Optional[str] = None\n",
    "    errorDetail: Optional[List[str]] = None\n",
    "        \n",
    "        \n",
    "@dataclass\n",
    "class AssetTableModel:\n",
    "    name: str\n",
    "    columns: List[str]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AssetModel:\n",
    "    name: str\n",
    "    tables: List[AssetTableModel]\n",
    "    rootTable: str\n",
    "    rootColumn: str\n",
    "    follow: Optional[List[str]] = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RelationshipTermModel:\n",
    "    table: str\n",
    "    column: str\n",
    "\n",
    "        \n",
    "@dataclass_json\n",
    "@dataclass\n",
    "class RelationshipModel:\n",
    "    name: str\n",
    "    relationshipFrom: RelationshipTermModel = field(metadata=config(field_name=\"from\"))\n",
    "    to: RelationshipTermModel\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class IntPartitionOptionsModel:\n",
    "    column: str\n",
    "    min: int\n",
    "    max: int\n",
    "    interval: int\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DatePartitionOptionsModel:\n",
    "    column: Optional[str] = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ColumnModel:\n",
    "    name: str\n",
    "    datatype: DataTypeEnum\n",
    "    array_of: Optional[bool] = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TableModel:\n",
    "    name: str\n",
    "    columns: List[ColumnModel]\n",
    "    primaryKey: Optional[List[str]] = None\n",
    "    partitionMode: Optional[ParititionModeEnum] = None\n",
    "    datePartitionOptions: Optional[DatePartitionOptionsModel] = None\n",
    "    intPartitionOptions: Optional[IntPartitionOptionsModel] = None\n",
    "    rowCount: Optional[int] = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SchemaModel:\n",
    "    tables: List[TableModel]\n",
    "    relationships: Optional[List[RelationshipModel]] = None\n",
    "    assets: Optional[List[AssetModel]] = None\n",
    "\n",
    "@dataclass\n",
    "class Storage:\n",
    "    region: Optional[str] = None\n",
    "    cloudResource: Optional[str] = None\n",
    "    cloudPlatform: Optional[str] = None\n",
    "    \n",
    "@dataclass \n",
    "class BigQueryTable:\n",
    "    name: Optional[str] = None\n",
    "    id: Optional[str] = None\n",
    "    qualified_name: Optional[str] = None\n",
    "    link: Optional[str] = None\n",
    "    sampleQuery: Optional[str] = None\n",
    "\n",
    "@dataclass\n",
    "class BigQuery:\n",
    "    datasetName: Optional[str] = None\n",
    "    datasetId: Optional[str] = None\n",
    "    projectId: Optional[str] = None\n",
    "    link: Optional[str] = None\n",
    "    tables: Optional[List[BigQueryTable]] = None\n",
    "\n",
    "@dataclass\n",
    "class ParquetTable:\n",
    "    name: Optional[str] = None\n",
    "    url: Optional[str] = None\n",
    "    sasToken: Optional[str] = None\n",
    "\n",
    "@dataclass\n",
    "class Parquet:\n",
    "    datasetName: Optional[str] = None\n",
    "    datasetId: Optional[str] = None\n",
    "    storageAccountId: Optional[str] = None\n",
    "    url: Optional[str] = None\n",
    "    sasTtoken: Optional[str] = None\n",
    "    tables: Optional[List[ParquetTable]] = None\n",
    "        \n",
    "@dataclass\n",
    "class AccessInformation:\n",
    "    bigQuery: Optional[BigQuery] = None\n",
    "    parquet: Optional[Parquet] = None\n",
    "        \n",
    "\n",
    "@dataclass\n",
    "class Item:\n",
    "    id: Optional[str] = None\n",
    "    name: Optional[str] = None\n",
    "    description: Optional[str] = None\n",
    "    defaultProfileId: Optional[str] = None\n",
    "    createdDate: Optional[str] = None\n",
    "    storage: Optional[List[Storage]] = None\n",
    "    secureMonitoringEnabled: Optional[bool] = None\n",
    "    cloudPlatform: Optional[str] = None\n",
    "    dataProject: Optional[str] = None\n",
    "    storageAccount: Optional[str] = None\n",
    "    phsId: Optional[str] = None\n",
    "    selfHosted: Optional[bool] = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RoleMap:\n",
    "    additional_prop1: List[str]\n",
    "\n",
    "@dataclass_json\n",
    "@dataclass\n",
    "class TDRDatasetDetail:\n",
    "    id: Optional[str] = None\n",
    "    name: Optional[str] = None\n",
    "    description: Optional[str] = None\n",
    "    defaultProfileId: Optional[str] = None\n",
    "    dataProject: Optional[str] = None\n",
    "    defaultSnapshotId: Optional[str] = None\n",
    "    schema: Optional[SchemaModel] = None\n",
    "    storage: Optional[List[Storage]] = None\n",
    "    secureMonitoringEnabled: Optional[bool] = None\n",
    "    phsId: Optional[str] = None\n",
    "    accessInformation: Optional[AccessInformation] = None\n",
    "    selfHosted: Optional[bool] = None\n",
    "    \n",
    "        \n",
    "@dataclass_json\n",
    "@dataclass\n",
    "class TDRDataset:\n",
    "    total: int\n",
    "    filteredTotal: int\n",
    "    items: List[Item]\n",
    "    roleMap: RoleMap\n",
    "        \n",
    "        \n",
    "@dataclass\n",
    "class TDRDatasetSearchRequest:\n",
    "    filter: Optional[str] = None\n",
    "    sort: Optional[int] = None\n",
    "    direction: Optional[int] = None\n",
    "        \n",
    "\n",
    "@dataclass\n",
    "class TDRDatasetRequest:\n",
    "    name: str\n",
    "    defaultProfileId: str\n",
    "    schema: SchemaModel\n",
    "    description: Optional[str] = None\n",
    "    region: Optional[str] = None\n",
    "    cloudPlatform: Optional[CloudPlatformEnum] = None\n",
    "    enableSecureMonitoring: Optional[bool] = None\n",
    "    phsId: Optional[str] = None\n",
    "    experimentalSelfHosted: Optional[bool] = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TDRIngestRequest:\n",
    "    table: str\n",
    "    format: FormatEnum\n",
    "    path: Optional[str] = None\n",
    "    records: Optional[List[str]] = None\n",
    "    load_tag: Optional[str] = None\n",
    "    profile_id: Optional[str] = None\n",
    "    max_bad_records: Optional[int] = None\n",
    "    max_failed_file_loads: Optional[int] = None\n",
    "    ignore_unknown_values: Optional[bool] = None\n",
    "    csv_field_delimiter: Optional[str] = None\n",
    "    csv_quote: Optional[str] = None\n",
    "    csv_skip_leading_rows: Optional[int] = None\n",
    "    csv_allow_quoted_newlines: Optional[bool] = None\n",
    "    csv_null_marker: Optional[str] = None\n",
    "    csv_generate_row_ids: Optional[bool] = None\n",
    "    resolve_existing_files: Optional[bool] = None\n",
    "    transactionId: Optional[str] = None\n",
    "    updateStrategy: Optional[UpdateEnum] = None\n",
    "\n",
    "\n",
    "def as_dict(obj):\n",
    "    return {\n",
    "        field: value.value if isinstance(value, Enum) else value for field, value in obj if value is not None\n",
    "    }\n",
    "\n",
    "\n",
    "class TDRClient(AuthenticatedClient):\n",
    "    \"\"\"Client for interfacing with the TDR.\n",
    "\n",
    "    Enables communication via the TDR API:\n",
    "    https://data.terra.bio/\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        host=os.environ.get(\"ZEBRAFISH_TDR_HOST\", \"data.terra.bio\"),\n",
    "        token=os.environ.get(\"ZEBRAFISH_TDR_TOKEN\"),\n",
    "        scheme=\"https\",\n",
    "    ):\n",
    "        if token is None:\n",
    "            print(\"TDRClient has no authentication token.\")\n",
    "\n",
    "        self.host = host\n",
    "        self.token = token\n",
    "        self.scheme = scheme\n",
    "\n",
    "    def _build_url(self, path: str) -> str:\n",
    "        \"\"\"Build url and ensure it is structured correctly.\"\"\"\n",
    "        url = f\"{self.scheme}://{self.host}/{path}\"\n",
    "        parts = urlparse(url)\n",
    "        return urlunparse(parts._replace(path=quote(parts.path.replace(\"//\", \"/\"))))\n",
    "\n",
    "    def authenticate(self, request: Request) -> Request:\n",
    "        \"\"\"Prepare request with appropriate authorization inforamtion.\"\"\"\n",
    "        if self.token:\n",
    "            request.headers.update({\"Authorization\": f\"Bearer {self.token}\"})\n",
    "        return request\n",
    "\n",
    "    def handle_response(\n",
    "        self, response: Response, success_code: List[int]\n",
    "    ) -> TDRResponse:\n",
    "        \"\"\"Handles response based on given success_code\"\"\"\n",
    "        \n",
    "        if response.status_code not in success_code:\n",
    "            msg = response.text if response.text else response.message\n",
    "            print(f\"msg = {msg}\")\n",
    "            raise Exception(f\"Request failed: {response.status_code}\")\n",
    "\n",
    "        return TDRResponse(**response.json())\n",
    "    \n",
    "    def check_job_polling_response(self, response):\n",
    "        return self.handle_response(response, [200, 202]).completed is not None\n",
    "    \n",
    "    def create_dataset(self, req: TDRDatasetRequest) -> TDRResponse:\n",
    "        \"\"\"Create a new dataset.\"\"\"\n",
    "        url = self._build_url(\"/api/repository/v1/datasets\")\n",
    "        params = {\"json\": asdict(req, dict_factory=as_dict)}\n",
    "        return self.handle_response(self.send(self._post(url, **params)), [200, 202])\n",
    "    \n",
    "    def get_dataset_by_name(self, req: TDRDatasetSearchRequest) -> TDRDataset:\n",
    "        \"\"\"Get dataset by name\"\"\"\n",
    "        params = {\"params\": asdict(req, dict_factory=as_dict)}\n",
    "        url = self._build_url(\"/api/repository/v1/datasets\")\n",
    "\n",
    "        response = self.send(self._get(url, **params))\n",
    "        \n",
    "        if response.status_code not in [200]:\n",
    "            msg = response.text if response.text else response.message\n",
    "            print(msg)\n",
    "            raise Exception(f\"Request failed: {response.status_code}\")\n",
    "    \n",
    "        return TDRDataset(**response.json())\n",
    "    \n",
    "    def get_dataset_details(self, id: str) -> TDRDataset:\n",
    "        \"\"\"Get dataset by name\"\"\"\n",
    "        url = self._build_url(f\"/api/repository/v1/datasets/{id}?include=ACCESS_INFORMATION\")\n",
    "\n",
    "        response = self.send(self._get(url))\n",
    "                \n",
    "        if response.status_code not in [200]:\n",
    "            msg = response.text if response.text else response.message\n",
    "            print(msg)\n",
    "            raise Exception(f\"Request failed: {response.status_code}\")\n",
    "    \n",
    "        return TDRDatasetDetail.from_json(json.dumps(response.json()))\n",
    "\n",
    "    def job_status(self, id: str) -> TDRResponse:\n",
    "        \"\"\"Get TDR Job Status.\"\"\"\n",
    "        url = self._build_url(f\"/api/repository/v1/jobs/{id}\")\n",
    "\n",
    "        # 200 = ok, 202 = running\n",
    "        return self.handle_response(self.send(self._get(url)), [200, 202])\n",
    "    \n",
    "    def job_status_result(self, id: str) -> TDRErrorResponse:\n",
    "        \"\"\"Get TDR Job Status.\"\"\"\n",
    "        url = self._build_url(f\"/api/repository/v1/jobs/{id}/result\")\n",
    "        response = self.send(self._get(url))\n",
    "        \n",
    "        # 200 = ok, 202 = running\n",
    "        return TDRErrorResponse(**response.json())\n",
    "    \n",
    "    def poll_job_status(self, id: str) -> TDRResponse:\n",
    "        \"\"\"Poll TDR Job Status until Job is completed\"\"\"\n",
    "        url = self._build_url(f\"/api/repository/v1/jobs/{id}\")\n",
    "\n",
    "        # Poll until completed value is not None\n",
    "        resp = polling2.poll(\n",
    "            lambda: self.send(self._get(url)),\n",
    "            check_success=self.check_job_polling_response,\n",
    "            step=30,\n",
    "            poll_forever=True,\n",
    "        )\n",
    "        \n",
    "        # If \"job_status\": \"failed\" get the result details -- else send regular response\n",
    "        if self.handle_response(resp, [200]).job_status == \"failed\":\n",
    "            return self.job_status_result(id)\n",
    "        else:\n",
    "            return self.handle_response(resp, [200])\n",
    "\n",
    "    def ingest(self, id: str, req: TDRIngestRequest) -> TDRResponse:\n",
    "        \"\"\"Ingest\"\"\"\n",
    "\n",
    "        url = self._build_url(f\"/api/repository/v1/datasets/{id}/ingest\")\n",
    "\n",
    "        params = {\"json\": asdict(req, dict_factory=as_dict)}\n",
    "        \n",
    "        print(f\"params: {params}\")\n",
    "        return self.handle_response(self.send(self._post(url, **params)), [200, 202])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
